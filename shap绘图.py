"""
================================================================================
éå‚æ•°æœºå™¨å­¦ä¹ ä¸é«˜çº§SHAPå¯è§†åŒ–è„šæœ¬
================================================================================
å·¥ä½œå†…å®¹ï¼š
    1. ç»§æ‰¿åŸå§‹æ•°æ®å¤„ç†ã€éšæœºæ£®æ—è®­ç»ƒåŠVIFã€Group Importanceè®¡ç®—é€»è¾‘ã€‚
    2. æ•´åˆå‚è€ƒç»˜å›¾ä»£ç ï¼Œåˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„ç»„åˆå¯è§†åŒ–å›¾è¡¨ï¼ˆç«ç‘°å›¾+æ¡å½¢å›¾+èœ‚ç¾¤å›¾ï¼‰ã€‚
    3. å°†ç»“æœä¿å­˜è‡³æŒ‡å®šè·¯å¾„ D:\1sdgplanning\5fig

å·¥ç¨‹å¸ˆï¼š[Your Name/Role as an experienced Python Engineer]
æ—¥æœŸï¼š2023-x-x (åŸºäºå½“å‰è¯·æ±‚)
================================================================================
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor
import shap
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.colors as mcolors
from matplotlib.cm import ScalarMappable
import os
import warnings

# å¿½ç•¥shapè®¡ç®—æ—¶çš„ä¸€äº›ä¸å¿…è¦è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)

# ==========================================
# 0. å…¨å±€è®¾ç½® (Matplotlib & Paths)
# ==========================================
# é˜²æ­¢ä¸­æ–‡å­—ä½“æ˜¾ç¤ºæŠ¥é”™ï¼Œå°è¯•åŒ¹é…ç³»ç»Ÿä¸­å­˜åœ¨çš„ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'Microsoft YaHei', 'DejaVu Sans'] 
plt.rcParams['axes.unicode_minus'] = False
# è®¾ç½®å…¨å±€å­—ä½“å¤§å°ï¼Œä½¿å…¶æ›´æ¸…æ™°
plt.rcParams['font.size'] = 12


# è·¯å¾„è®¾ç½®
input_file = r"D:\1sdgplanning\1data\1ç»Ÿè®¡æ•°æ®åŒ¹é….xlsx"
# åŸå§‹å›å½’ç»“æœä¿ç•™ç›®å½•
output_dir_data = r"D:\1sdgplanning\1data\å›å½’ç»“æœ"
# **ç”¨æˆ·æŒ‡å®šçš„æ–°å›¾åƒä¿å­˜ç›®å½•**
output_dir_fig = r"D:\1sdgplanning\5fig"

# ç¡®ä¿ç›®å½•å­˜åœ¨
for d in [output_dir_data, output_dir_fig]:
    if not os.path.exists(d):
        os.makedirs(d)

print(f"ç³»ç»Ÿå°±ç»ªã€‚æ•°æ®è¾“å…¥: {input_file}")
print(f"æ•°æ®ç»“æœè¾“å‡º: {output_dir_data}")
print(f"å›¾åƒç»“æœè¾“å‡º: {output_dir_fig}")

# ==========================================
# 1. æ•°æ®å‡†å¤‡ (ç»§æ‰¿åŸå§‹ä»£ç )
# ==========================================
print("\n" + "="*30)
print(" æ­¥éª¤ 1: æ•°æ®åŠ è½½ä¸é¢„å¤„ç†")
print("="*30)

df = pd.read_excel(input_file, sheet_name='data')
y_col = 'total'

# --- å˜é‡åˆ†ç»„ä¸å¯¹æ•°åŒ–å¤„ç† ---
vars_to_log = [
    'population', 'education', 'hospital', 'library', 'property', 'gdp', 
    'expenditure', 'buildup', 'water', 'sci_expend', 'edu_expend', 'export', 'high_way'
]

# æ‰§è¡Œå¯¹æ•°åŒ–ï¼Œä½†ã€ä¸åˆ é™¤ã€‘åŸå˜é‡
for v in vars_to_log:
    if v in df.columns:
        df[f'ln_{v}'] = np.log(df[v] + 1)

# å°†å…¨é‡æŒ‡æ ‡ç³»ç»Ÿåœ°åˆ†é…åˆ°ä¸‰å¤§ç»´åº¦ä¸­
layer1_baseline = ['population', 'gdp',  'ln_buildup']
layer2_spatial = ['ln_high_way', 'elevation_mean', 'slope_mean', 'ln_water', 'rain', 'yangtze_river', 'yellow_river', 'hu_line', 'coastal']
layer3_policy = ['ln_sci_expend', 'ln_edu_expend', 'pro_capital', 'big_city', 'pilot_eco', 'pilot_fdi', 'pilot_ecosupervison', 'pilot_inno', 'pilot_urban', 'pilot_resilience', 'pilot_15min']

# åˆ›å»ºç‰¹å¾åç§°åˆ°ç»„åçš„æ˜ å°„å­—å…¸ï¼Œç”¨äºç»˜å›¾é…è‰²
feature_group_map = {}
for feat in layer1_baseline: feature_group_map[feat] = 'Baseline'
for feat in layer2_spatial: feature_group_map[feat] = 'Spatial'
for feat in layer3_policy: feature_group_map[feat] = 'Policy'

# åˆå¹¶æ‰€æœ‰ç‰¹å¾ï¼Œå¹¶ç¡®ä¿å®ƒä»¬åœ¨æ•°æ®é›†ä¸­ç¡®å®å­˜åœ¨
all_features_raw = layer1_baseline + layer2_spatial + layer3_policy
all_features = [f for f in all_features_raw if f in df.columns]

df_clean = df.dropna(subset=[y_col] + all_features).copy()

# æ ‡å‡†åŒ–å¤„ç†ï¼šä»…é’ˆå¯¹å…·æœ‰5ä¸ªä»¥ä¸Šå”¯ä¸€å€¼çš„è¿ç»­å˜é‡
continuous_features = [f for f in all_features if df_clean[f].nunique() > 5]
scaler = StandardScaler()
df_clean[continuous_features] = scaler.fit_transform(df_clean[continuous_features])

X = df_clean[all_features]
y = df_clean[y_col]

# ==========================================
# 2. å¤šé‡å…±çº¿æ€§è¯Šæ–­ (VIF) (ç»§æ‰¿åŸå§‹ä»£ç )
# ==========================================
print("\n" + "="*30)
print(" æ­¥éª¤ 2: å¤šé‡å…±çº¿æ€§è¯Šæ–­ (VIF)")
print("="*30)

X_vif = sm.add_constant(X)
vif_data = pd.DataFrame()
vif_data["Variable"] = X_vif.columns
vif_data["VIF"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]

vif_data = vif_data[vif_data["Variable"] != "const"].sort_values(by="VIF", ascending=False)
vif_output_path = os.path.join(output_dir_data, "VIF_Results_Full.xlsx")
vif_data.to_excel(vif_output_path, index=False)
print(f"-> VIF ç»“æœ (Top 5):\n{vif_data.head(5)}")
print(f"-> å…¨å˜é‡ VIF ç»“æœå·²ä¿å­˜è‡³: {vif_output_path}")

# ==========================================
# 3. è®­ç»ƒæ¨¡å‹ä¸ç²¾åº¦è¯„ä¼° (ç»§æ‰¿åŸå§‹ä»£ç )
# ==========================================
print("\n" + "="*30)
print(" æ­¥éª¤ 3: è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹")
print("="*30)
print(f" æœ‰æ•ˆæ ·æœ¬é‡: {len(df_clean)} | çº³å…¥ç‰¹å¾æ€»æ•°: {len(all_features)}")

# å‚è€ƒç»˜å›¾ä»£ç å»ºè®®ï¼Œæ·»åŠ  n_jobs=-1 åŠ é€Ÿè®¡ç®—
rf_model = RandomForestRegressor(n_estimators=1000, max_depth=15, min_samples_leaf=2, random_state=42, oob_score=True, n_jobs=-1)
rf_model.fit(X, y)

y_pred = rf_model.predict(X)
oob_r2 = rf_model.oob_score_
print(f"-> æ¨¡å‹è®­ç»ƒå®Œæˆã€‚OOB RÂ²: {oob_r2:.4f}, è®­ç»ƒé›† RÂ²: {r2_score(y, y_pred):.4f}")

# ==========================================
# 4. è®¡ç®— SHAP å€¼ (ç»§æ‰¿åŸå§‹ä»£ç )
# ==========================================
print("\n" + "="*30)
print(" æ­¥éª¤ 4: è®¡ç®— SHAP å€¼")
print("="*30)
explainer = shap.TreeExplainer(rf_model)
# æ³¨æ„ï¼šç›´æ¥ä¼ å…¥æ ‡å‡†åŒ–åçš„X
shap_values_array = explainer.shap_values(X)
# åˆ›å»º Explanation å¯¹è±¡ï¼Œç”¨äº summary_plot
shap_explanation = explainer(X)

# ==========================================
# 5. è®¡ç®—ç»´åº¦è´¡çŒ®åº¦ (ç»§æ‰¿/ä¿®æ­£åŸå§‹ä»£ç é€»è¾‘)
# ==========================================
print("\n" + "="*30)
print(" æ­¥éª¤ 5: è®¡ç®—ç›¸å¯¹é‡è¦æ€§ä¸ç»´åº¦è´¡çŒ®")
print("="*30)

# è®¡ç®—å•ä¸ªå˜é‡çš„ Mean(|SHAP|)
shap_abs_mean = np.mean(np.abs(shap_values_array), axis=0)
importance_df = pd.DataFrame({'Variable': X.columns, 'Importance': shap_abs_mean})
total_global_impact = importance_df['Importance'].sum()

# æ„å»ºåˆ†ç»„å¯¼å‡ºåˆ—è¡¨
group_results = []
groups_data = [
    ('1_Baseline Development', layer1_baseline), 
    ('2_Spatial & Natural', layer2_spatial), 
    ('3_Policy & Intervention', layer3_policy)
]

for group_name, group_vars in groups_data:
    valid_vars = [v for v in group_vars if v in X.columns]
    group_imp = importance_df[importance_df['Variable'].isin(valid_vars)]['Importance'].sum()
    group_pct = (group_imp / total_global_impact) * 100
    
    group_results.append({
        'Group_Name': group_name,
        'Total_Importance': group_imp,
        'Contribution_Percentage(%)': group_pct,
        'Variables': valid_vars # ä¿ç•™åˆ—è¡¨ä¾›ç»˜å›¾ä½¿ç”¨
    })

# --- æ‰“å°å¹¶å¯¼å‡ºç»„åˆ«ç»“è®º ---
print(" ğŸ† ä¸‰å¤§ç»´åº¦é©±åŠ¨åŠ›å æ¯”:")
for res in group_results:
    print(f" - {res['Group_Name']}: {res['Contribution_Percentage(%)']:.2f}%")

group_df = pd.DataFrame(group_results)
group_df_export = group_df.copy()
group_df_export['Included_Variables'] = group_df_export['Variables'].apply(lambda x: ", ".join(x))
group_output_path = os.path.join(output_dir_data, "Group_Importance_Results.xlsx")
group_df_export.drop(columns=['Variables']).to_excel(group_output_path, index=False)

# --- å¯¼å‡ºæ‰€æœ‰å•ä¸ªå˜é‡çš„è´¡çŒ®ç»“æœ ---
importance_df['Contribution_Percentage(%)'] = (importance_df['Importance'] / total_global_impact) * 100
importance_df = importance_df.sort_values(by='Importance', ascending=False)
importance_output_path = os.path.join(output_dir_data, "SHAP_Importance_Results_Full.xlsx")
importance_df.to_excel(importance_output_path, index=False)


# ==========================================
# 6. é«˜çº§ç»„åˆç»˜å›¾ (å‚è€ƒç»˜å›¾ä»£ç å®ç°)
# ==========================================
print("\n" + "="*30)
print(" æ­¥éª¤ 6: ç»˜åˆ¶ SHAP ç»„åˆå›¾ (å‚è€ƒå‚è€ƒä»£ç å¸ƒå±€)")
print("="*30)

# ç»˜å›¾é…ç½® (å‚è€ƒä»£ç è®¾å®š)
SELECTED_COLOR_SCHEME = 'coolwarm' # é€‰æ‹© coolwarm é…è‰²
CMAP_BASE = plt.cm.get_cmap(SELECTED_COLOR_SCHEME)
MAX_DISPLAY = 15 # å›¾ä¸­å±•ç¤ºå‰15ä¸ªå˜é‡ï¼Œé¿å…æ‹¥æŒ¤

# å®šä¹‰ç»„åˆ«çš„å›ºå®šé…è‰² (ç”¨äºæ¡å½¢å›¾å’Œç«ç‘°å›¾å†…éƒ¨)
group_colors_map = {
    'Baseline': '#4e79a7', # è«å…°è¿ªè“
    'Spatial': '#59a14f',  # è«å…°è¿ªç»¿
    'Policy': '#edc948'   # è«å…°è¿ªé»„
}

def plot_shap_combined(X_df, shap_values, explanation, importance_df, group_results, feature_group_map, save_path):
    """
    åˆ›å»ºä¸€ä¸ªå¤æ‚çš„è‡ªå®šä¹‰ç»„åˆå›¾ï¼šå·¦ä¾§åµŒå…¥ç«ç‘°å›¾çš„æ¡å½¢å›¾ï¼Œå³ä¾§å¯¹é½çš„èœ‚ç¾¤å›¾ã€‚
    """
    # 1. æ•°æ®å‡†å¤‡ (ç”¨äºæ¡å½¢å›¾å’Œèœ‚ç¾¤å›¾æ’åº)
    top_df = importance_df.head(MAX_DISPLAY).copy()
    sorted_features = top_df['Variable'].tolist()
    sorted_idx = [X_df.columns.get_loc(f) for f in sorted_features]
    
    # å‡†å¤‡æ¡å½¢å›¾é¢œè‰² (æ ¹æ®å˜é‡æ‰€åœ¨ç»„)
    bar_colors = [group_colors_map[feature_group_map[f]] for f in sorted_features]
    
    # 2. åˆ›å»ºç”»å¸ƒ
    fig = plt.figure(figsize=(22, 12)) # å®½å¹…ç”»å¸ƒ

    # å…¨å±€åæ ‡å‚æ•° (Normalized 0-1)
    plot_bottom = 0.1
    plot_height = 0.8
    space_between = 0.04
    
    # 3. è®¡ç®—åæ ‡è½´ä½ç½® (ç²¾ç»†æ§åˆ¶)
    # [left, bottom, width, height]
    # A. ä¸­å¤®æ¡å½¢å›¾ (Bar Plot) - ä½œä¸ºæ ¸å¿ƒåŸºå‡†
    bar_width = 0.25
    bar_left = 0.38 
    ax_bar = fig.add_axes([bar_left, plot_bottom, bar_width, plot_height])
    
    # B. åµŒå…¥å¼ç«ç‘°å›¾ (Radial Inset) - æ”¾åœ¨æ¡å½¢å›¾å·¦ä¾§åä¸‹çš„ä½ç½®
    radial_size = 0.32 # ç¨å¾®å¤§ä¸€ç‚¹
    radial_left = bar_left - radial_size + 0.05
    radial_bottom = plot_bottom + 0.05
    # åˆ›å»ºæåæ ‡ç³»è½´
    ax_radial = fig.add_axes([radial_left, radial_bottom, radial_size, radial_size], projection='polar')

    # C. å³ä¾§èœ‚çªå›¾ (Beeswarm Plot)
    beeswarm_left = bar_left + bar_width + space_between
    beeswarm_width = 0.32
    ax_beeswarm = fig.add_axes([beeswarm_left, plot_bottom, beeswarm_width, plot_height])

    # D. Colorbar for Beeswarm
    cbar_width = 0.01
    cbar_left = beeswarm_left + beeswarm_width + 0.01
    ax_cbar = fig.add_axes([cbar_left, plot_bottom + plot_height*0.2, cbar_width, plot_height*0.6])

    # ---ç»˜å›¾å¼€å§‹---

    print(" -> ç»˜åˆ¶ä¸­å¤®æ¡å½¢å›¾ä¸ç»´åº¦é…è‰²...")
    # --- A. ä¸­å¤®æ¡å½¢å›¾ (ax_bar) ---
    y_pos = np.arange(len(sorted_features))
    ax_bar.barh(y_pos, top_df['Importance'], color=bar_colors, height=0.7, edgecolor='none', alpha=0.9)
    
    # è®¾ç½®æ¡å½¢å›¾æ ·å¼ (å‚è€ƒä»£ç è¦æ±‚)
    ax_bar.set_yticks(y_pos)
    ax_bar.set_yticklabels(sorted_features, fontsize=16)
    ax_bar.invert_yaxis() # é¡¶éƒ¨æ˜¾ç¤ºæœ€é‡è¦çš„
    ax_bar.set_xlabel('Mean(|SHAP Value|) - Relative Importance', fontsize=18, labelpad=10)
    
    # ä¿®æ”¹è¾¹æ¡†ç²—ç»† (å‚è€ƒä»£ç  linewidth=3)
    ax_bar.spines['left'].set_visible(False)
    ax_bar.spines['top'].set_visible(False)
    ax_bar.spines['right'].set_linewidth(3)
    ax_bar.spines['bottom'].set_linewidth(3)
    ax_bar.tick_params(axis='x', labelsize=16, direction='in', length=6, width=2)
    ax_bar.tick_params(axis='y', length=0) # éšè—yè½´åˆ»åº¦çº¿ï¼Œä¿ç•™æ ‡ç­¾
    
    # æ·»åŠ ç½‘æ ¼çº¿
    ax_bar.grid(axis='x', linestyle='--', alpha=0.5)

    print(" -> ç»˜åˆ¶åµŒå…¥å¼ç»´åº¦ç«ç‘°å›¾...")
    # --- B. åµŒå…¥å¼ç«ç‘°å›¾ (ax_radial) ---
    num_groups = len(group_results)
    # è®¡ç®—è§’åº¦ (Nå¯, é¡ºæ—¶é’ˆ)
    angles = np.linspace(0, 2 * np.pi, num_groups, endpoint=False)
    widths = np.diff(angles, append=2*np.pi) # æ¯ä¸ªæ‰‡å½¢çš„å®½åº¦
    
    percentages = [res['Contribution_Percentage(%)'] for res in group_results]
    # æ¸…ç®€ç»„åä¾›æ˜¾ç¤º
    group_labels_clean = [res['Group_Name'].split('_')[-1] for res in group_results]
    # ç«ç‘°å›¾å†…éƒ¨é…è‰² (ä¸æ¡å½¢å›¾ç»„åˆ«ä¸€è‡´)
    radial_inner_colors = [group_colors_map[res['Group_Name'].split('_')[-1].split(' ')[0]] for res in group_results]

    # ç»˜åˆ¶åŸºç¡€ç¯ (é«˜åº¦ä»£è¡¨ç™¾åˆ†æ¯”)
    bars = ax_radial.bar(angles, percentages, width=widths, bottom=0.0, 
                          color=radial_inner_colors, alpha=0.8, edgecolor='white', linewidth=2, align='edge')
    
    # è®¾ç½®æåæ ‡ç³»æ ·å¼
    ax_radial.set_theta_zero_location('N') # åŒ—ç‚¹ä¸º0
    ax_radial.set_theta_direction(-1)      # é¡ºæ—¶é’ˆ
    ax_radial.set_yticklabels([])          # éšè—å¾„å‘åˆ»åº¦
    ax_radial.set_xticklabels([])          # éšè—è§’åº¦åˆ»åº¦
    ax_radial.spines['polar'].set_visible(False) # éšè—å¤–åœˆ
    ax_radial.grid(False)
    
    # ç«ç‘°å›¾ä¸­å¿ƒæ·»åŠ æ ‡é¢˜
    ax_radial.text(0, 0, 'Dimension\nContrib.', ha='center', va='center', fontsize=14, fontweight='bold')

    # æ·»åŠ ç™¾åˆ†æ¯”å’Œç»„åæ ‡ç­¾
    for angle, p, label, w, res in zip(angles, percentages, group_labels_clean, widths, group_results):
        # è®¡ç®—æ ‡ç­¾ä½ç½® (æ‰‡å½¢ä¸­é—´)
        label_angle = angle + w/2
        # æ”¾ç½®ç™¾åˆ†æ¯”
        ax_radial.text(label_angle, p + 5, f'{p:.1f}%', ha='center', va='center', fontsize=14, fontweight='bold')
        # æ”¾ç½®ç»„å (ç¨å¾®è¿œä¸€ç‚¹)
        ax_radial.text(label_angle, p + 25, label, ha='center', va='center', fontsize=13, color='black')

    # æ·»åŠ ç«ç‘°å›¾æ ‡é¢˜
    ax_bar.text(-0.8, 0.45, 'Dimension Driver\nContribution (Rose Plot)', transform=ax_bar.transAxes, 
                fontsize=16, fontweight='bold', ha='center', va='center', bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))

    print(" -> ç»˜åˆ¶å³ä¾§SHAPèœ‚ç¾¤å›¾...")
    # --- C. å³ä¾§èœ‚çªå›¾ (ax_beeswarm) ---
    plt.sca(ax_beeswarm) # åˆ‡æ¢å½“å‰Axes
    
    # å¿…é¡»å¯¹ à¤à¤•à¥à¤¸à¤ªà¥à¤²à¥‡à¤¨à¥‡à¤¶à¤¨ æ•°æ®è¿›è¡Œæ’åºï¼Œä½¿å…¶ä¸æ¡å½¢å›¾yè½´å¯¹é½
    # æå–æ’åºåçš„SHAPå€¼çŸ©é˜µå’Œæ•°æ®çŸ©é˜µ
    shap_values_sorted = shap_values[:, sorted_idx]
    X_data_sorted = X_df.iloc[:, sorted_idx]
    
    # ä½¿ç”¨ shap è‡ªå¸¦å‡½æ•°ç»˜åˆ¶ï¼Œshow=False
 # ä½¿ç”¨ shap è‡ªå¸¦å‡½æ•°ç»˜åˆ¶ï¼Œshow=False
    shap.summary_plot(
        shap_values_sorted, 
        X_data_sorted, 
        plot_type="dot", 
        cmap=CMAP_BASE,     # ã€ä¿®æ­£1ã€‘ç‚¹å›¾ä½¿ç”¨ cmap è€Œä¸æ˜¯ color
        max_display=MAX_DISPLAY, 
        show=False, 
        plot_size=None,     # ç”± axes æ§åˆ¶
        color_bar=False     # ã€ä¿®æ­£2ã€‘æ”¹ä¸ºå¸¦ä¸‹åˆ’çº¿çš„ color_bar
    )
 
    # è®¾ç½®èœ‚ç¾¤å›¾æ ·å¼
    ax_beeswarm.set_yticklabels([]) # éšè—yè½´æ ‡ç­¾ï¼ˆå·²åœ¨æ¡å½¢å›¾æ˜¾ç¤ºï¼‰
    ax_beeswarm.set_ylabel('')
    ax_beeswarm.set_xlabel("SHAP Value (Impact on SDG total)", fontsize=18, labelpad=10)
    ax_beeswarm.invert_yaxis() # å¿…é¡»åè½¬ï¼Œä¸æ¡å½¢å›¾å¯¹é½
    
    ax_beeswarm.spines['left'].set_visible(False)
    ax_beeswarm.spines['top'].set_visible(False)
    ax_beeswarm.spines['right'].set_visible(False)
    ax_beeswarm.spines['bottom'].set_linewidth(3)
    ax_beeswarm.tick_params(axis='x', labelsize=16, direction='in', length=6, width=2)
    ax_beeswarm.set_xlim(ax_beeswarm.get_xlim()) # é”å®šxlim

    # --- D. æ‰‹åŠ¨æ·»åŠ  Colorbar ---
    m = ScalarMappable(cmap=CMAP_BASE)
    m.set_array([0, 1]) # å½’ä¸€åŒ–ç‰¹å¾å€¼
    cb = fig.colorbar(m, cax=ax_cbar, ticks=[0, 1])
    cb.set_label('Feature Value', size=16, labelpad=-10)
    cb.ax.set_yticklabels(['Low', 'High'], fontsize=14)
    cb.outline.set_visible(False) # éšè—Colorbarè¾¹æ¡†

    # --- ç»„åˆå›¾å¤§æ ‡é¢˜ ---
    fig.suptitle('Drivers of SDG Heterogeneity: Group Contribution & Feature Impact', 
                 fontsize=26, fontweight='bold', y=0.96)

    # ä¿å­˜å›¾å½¢
    print(f" -> æ­£åœ¨ä¿å­˜ç»„åˆå›¾è‡³: {save_path} ...")
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close(fig)

# æ‰§è¡Œç»˜å›¾
final_fig_path = os.path.join(output_dir_fig, "shapç»„åˆå›¾.jpg")
plot_shap_combined(X, shap_values_array, shap_explanation, importance_df, group_results, feature_group_map, final_fig_path)

print("\nğŸ† å·¥ä½œå®Œæˆï¼")
print(f"âœ… ç›¸å¯¹é‡è¦æ€§æ•°æ®ç»“æœä¿å­˜åœ¨: {output_dir_data}")
print(f"âœ… é«˜çº§SHAPç»„åˆå›¾ä¿å­˜åœ¨: {final_fig_path}")